6월 12일 팀 프로젝트 시작
##### 공동 계획 및 공동 작업 과정
**목표** : 이탈 고객 예측을 통해 이탈 위험성을 가진 고객들의 이탈을 미연에 방지하기 위한 인사이트 제공
**작업 순서**
1. 데이터 선별
   - 케글, 공공 데이터 제공 및 데이터 분석 공모전 사이트 이용
   - 일주일 프로젝트이므로 주어진 기한 내에 끝낼 수 있도록 난이도 조절 필수
   - 결과적으로 케글에서 제공하는 통신사 이탈 예측 데이터 셋으로 선정

2. 데이터 전처리
   - 모두가 데이터 분석 프로젝트가 처음이었기 때문에 각자 전처리 작업을 수행할 수 있도록 계획
   - 개인의 전처리 결과물과 전처리 기준에 대해 토론
   - 동의된 부분에 있어서 통합하여 사용

3. EDA
   - 약 40 개에 해당하는 모든 컬럼에 대한 시각화 및 분석
  
4. 머신러닝 모델링
   - 예측 분석에 적합한 다양한 머신러닝 알고리즘에 대한 정보 수집
   - 각 알고리즘에 대한 적합성 판별을 위한 모델링 작업
       - 옵티마이징 없이 모델 학습
       - GridSearchCV를 이용해 파라미터 찾은 후 모델 재학습
       - ROC_AUC 점수를 기준으로 모델 선정
       - 최종적으로 XGB 사용

5. 인사이트 제공
  - 시각화 과정에서 얻은 결과물을 통해 인사이트 제공
  - 공동 결과물은 공동 PPT에 나와있다.

6. 발표

##### ??
초반 데이터 선별 과정에서 각자가 원하는 프로젝트 목표와 데이터셋을 제안했다.
본인은 모두의 난이도에 맞추어서 모두에게 적합한 난이도보다 조금은 높은 난이도를 가진 데이터셋 크기를 제안했고,
다른 팀원들의 검색력(?)으로 좋은 데이터셋들을 함께 검토해볼 수 있었다.
그 결과 케글에서 제공하는 통신사 이탈 예측 데이터셋으로 결정했다.

전처리와 EDA 과정은 모든 팀원이 각자가 할 수 있는 선에서 실습해볼 수 있는 것이 중요하다고 판단해서 하루 내지 이틀의 기간을 정해서
모두가 배운 것들을 실습할 수 있는 시간을 가졌다.
이 시간동안 서로의 공통된 방향이 없고 리드하는 사람이 뚜렷하게 없었기 때문에 약간의 혼란이 왔었고 내 경우에는 작업이 더디게 흘러갔다.
R이나 SPSS를 사용하는 통계분석에는 자신이 있었지만 분석할 데이터에 대한 시각화가 자동으로 이루어지는 프로그램을 주로 썼다보니
직접 시각화는 거의 처음이다. 그래서 더더욱 작업이 더딜 수밖에 없었던 것 같다.
시각화 부분에서는 다른 팀원들의 작업물을 보고 이해하면서 다음 단계로 넘어갔다.
모델링을 할 때의 내가 했던 작업들은 예측 분석을 위한 머신러닝 알고리즘에 대한 정보를 수집했고,
LogisticRegression, DecisionTree, RandomForest, GradientBoosting, XGBoosting, LightGBM, Stacking, Bagging, Voting 등
우리의 예측 모델에 적합해보이는 알고리즘으로 지정했다.
우리의 데이터셋은 타겟의 비율이 불균형했기 때문에 알고리즘을 선택하는 기준으로 Accuracy 대신 ROC_AUC 점수로 정했다.
각 알고리즘에 대한 점수는 파라미터를 선정하기 전에도 높았지만 점수를 높이기 위해 최적의 파라미터를 찾고
특성 중요도를 적용해 모델 검증을 하며 최종적으로 XGB 알고리즘으로 선택했다.

나는 프로젝트 기간동안 시각화에 대한 역량 부족을 보완하기 위해 프로젝트가 끝난 이후에 공동 작업물에 추가적으로 EDA를 실습했다.
프로젝트가 끝난 후 발표에서 우리가 말하고자 하는 key point가 명확하지 않다는 피드백을 받았던 점을 고려해서
추가적으로 EDA를 수행하면서 개인적인 인사이트를 제공하고자 했다. 그와 관련한 파일과 내가 작성한 모델링 코드를 이 파일에 따로 올려두었다.
